{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf65594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "import json\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\" \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "\n",
    "\n",
    "from pprint import pprint as pprint\n",
    "from typing import List, Optional\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf075789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3288eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d85be909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from wiktionaryparser import WiktionaryParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348a5f61-ca8c-4e4e-ba7c-942e81b35f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_MODEL = \"ViT-B/32\"\n",
    "dictionary_type = 'compensate' # GPT_gen (DG or CADG), compensate (WN+DG or WN+CADG), wordnet (WN)\n",
    "GPT_def_path = 'Definitions/GPT_Context_Definitions.json' # definition path\n",
    "data_path = \"../Experimental Codes/Dataset/VWSD\" # data path\n",
    "\n",
    "d_split = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77836e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CLIP_model, preprocess = clip.load(CLIP_MODEL, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8ba511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(path, preprocessor):\n",
    "    img_files = os.listdir(path)\n",
    "    \n",
    "    imgs = {}\n",
    "    for file in tqdm(img_files):\n",
    "        file_path = os.path.join(path, file)\n",
    "        #img = preprocess(Image.open(\"CLIP.png\")).unsqueeze(0).to(device)\n",
    "        img = preprocess(Image.open(file_path)).unsqueeze(0)\n",
    "        imgs[file] = img\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcf578e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if d_split == 'trial': \n",
    "    image_path = data_path+\"/trial/all_images\"\n",
    "    data_file_path = data_path+\"/trial/trial.data.txt\"\n",
    "    gold_file_path = data_path+\"/trial/trial.gold.txt\"\n",
    "    image_dict_path = 'Temp/img_dict_trial.pkl'\n",
    "    \n",
    "elif d_split == 'train':\n",
    "    image_path = data_path+\"/train/train_v1/train_images_v1\"\n",
    "    data_file_path = data_path+\"/train/train_v1/train.data.v1.txt\"\n",
    "    gold_file_path = data_path+\"/train/train_v1/train.gold.v1.txt\"\n",
    "    \n",
    "    \n",
    "    image_dict_path = 'Temp/img_dict_train.pkl'\n",
    "\n",
    "\n",
    "\n",
    "if os.path.isfile(image_dict_path):\n",
    "    img_dict = pickle.load(open(image_dict_path,'rb'))\n",
    "else:\n",
    "    img_dict = image_loader(image_path,preprocess)\n",
    "    pickle.dump(img_dict, open(image_dict_path,'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8677bc8a-d28c-45d8-a772-0518bf338a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd02377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3de865-8b29-4f9a-8cac-b55da8f0dd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bac1a96e-633e-49f2-935e-89a76893c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT_definitions(object):\n",
    "    def __init__(self, GPT_def_path):\n",
    "        temp_dict = json.load(open(GPT_def_path))\n",
    "        \n",
    "        GPT_dict = {}\n",
    "        for key in temp_dict.keys():\n",
    "            for k in temp_dict[key]:\n",
    "                 GPT_dict[k] = []\n",
    "        for key in temp_dict.keys():\n",
    "            for k in temp_dict[key]:\n",
    "                 GPT_dict[k].append(temp_dict[key][k])\n",
    "        self.GPT_dict = GPT_dict\n",
    "        \n",
    "    def get_senses(self, target_word):\n",
    "        return self.GPT_dict[target_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8913fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary_wrapper(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        #self.dictionary_type=dict_type\n",
    "        \n",
    "        self.wn = wn\n",
    "        self.wiktionary_parser = WiktionaryParser()\n",
    "        self.GPT_definitions = GPT_definitions(GPT_def_path)\n",
    "        \n",
    "    def get_wn_definitions(self, target_word):\n",
    "        sense_definitions = []\n",
    "        target_senses = self.wn.synsets(target_word)\n",
    "        for synset in target_senses:\n",
    "            #if synset.pos() == 'n':\n",
    "            sense_definition = synset.definition().split(';')[0]\n",
    "            sense_definitions.append(sense_definition)\n",
    "        sense_definitions = list(set(sense_definitions))\n",
    "        \n",
    "        return sense_definitions\n",
    "        \n",
    "    def get_wiktionary_definitions(self, target_word, lang):\n",
    "        parser = self.wiktionary_parser\n",
    "        sense_definitions = []\n",
    "        \n",
    "        target_senses = parser.fetch(target_word, lang)\n",
    "        #print(target_senses)\n",
    "        for synset in target_senses:\n",
    "            #print(synset)\n",
    "            for polysemy in synset['definitions']:\n",
    "                #print(definition)\n",
    "                for sense in polysemy['text'][1:]:\n",
    "                    sense_definition = sense.split(';')[0]\n",
    "                    #print(sense_definition)\n",
    "                sense_definitions.append(sense_definition)\n",
    "        sense_definitions = list(set(sense_definitions))\n",
    "        \n",
    "        return sense_definitions\n",
    "    \n",
    "    def get_GPT_definitions(self, target_word, lang):\n",
    "        return self.GPT_definitions.get_senses(target_word)\n",
    "    \n",
    "    def get_definitions(self, target_word, dictionary_type = \"wordnet\", lang='english'):\n",
    "        # dictionary: wordnet, wiktionary, both\n",
    "        #print(dictionary_type)\n",
    "        if dictionary_type == 'wordnet':\n",
    "            sense_definitions = self.get_wn_definitions(target_word)\n",
    "        elif dictionary_type == 'GPT_gen':\n",
    "            sense_definitions = self.get_GPT_definitions(target_word, lang)\n",
    "        # elif dictionary_type == 'both':\n",
    "        #     sense_definitions = self.get_wn_definitions(target_word)\n",
    "        #     sense_definitions += self.get_GPT_definitions(target_word, lang)\n",
    "        elif dictionary_type == 'compensate':\n",
    "            sense_definitions = self.get_wn_definitions(target_word)\n",
    "            if len(sense_definitions) == 0:\n",
    "                sense_definitions += self.get_GPT_definitions(target_word, lang)\n",
    "        return sense_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc791e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b285c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d2a98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(data_file_path, dictionary, dictionary_type=\"wordnet\", gold_file_path = None):\n",
    "    \n",
    "    def target_word_preprocessing(target_word):\n",
    "        #target_word = target_word.replace('-',' ')\n",
    "        return target_word\n",
    "        \n",
    "    \n",
    "    text_data = {}\n",
    "    \n",
    "    fin_data = open(data_file_path)\n",
    "    candidate_lens = []\n",
    "    for data_index, line in tqdm(enumerate(fin_data)):\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        \n",
    "        cols = line.split('\\t')\n",
    "        target_word = cols[0]; target_word = target_word_preprocessing(target_word)\n",
    "        context = cols[1]\n",
    "        candidates = cols[2:]\n",
    "        \n",
    "        #sense_definitions = []\n",
    "        #target_senses = wn.synsets(target_word)\n",
    "        sense_definitions = dictionary.get_definitions(target_word, dictionary_type)\n",
    "        wordnet_definitions = dictionary.get_definitions(target_word, 'wordnet')\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        text_data[data_index] = {'target_word': target_word,\n",
    "                                 'sense_definitions': sense_definitions,\n",
    "                                 'wordnet_definitions': wordnet_definitions,\n",
    "                                 'context': context,\n",
    "                                 'candidates': candidates}\n",
    "\n",
    "        candidate_lens.append(len(candidates))\n",
    "    fin_data.close()\n",
    "    \n",
    "    \n",
    "    if gold_file_path:\n",
    "        fin_gold = open(gold_file_path)\n",
    "        for gold_index, line in enumerate(fin_gold):\n",
    "            line = line.strip()\n",
    "            if not line: continue\n",
    "            \n",
    "            gold = line\n",
    "            text_data[gold_index]['gold'] = gold\n",
    "    print(np.mean(candidate_lens))\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ebb997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12869it [00:06, 2141.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_data = data_loader(data_file_path, \n",
    "                        dictionary,\n",
    "                        dictionary_type,\n",
    "                        gold_file_path = gold_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c6f3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data_keys = list(text_data.keys())\n",
    "random.shuffle(text_data_keys)\n",
    "text_data_keys = text_data_keys\n",
    "text_data = {key: text_data[key] for key in text_data_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9d33ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4635200c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63bc8d8d-782c-4f35-a2b0-fd7c0b1ff511",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VWSD_CLIP_Zeroshot(object):\n",
    "    def __init__(self, CLIP_model, CLIP_preprocess):\n",
    "        self.CLIP_model = CLIP_model; \n",
    "        self.CLIP_preprocess = CLIP_preprocess\n",
    "    \n",
    "    def test(self, context, images):\n",
    "        CLIP_model = self.CLIP_model\n",
    "        CLIP_preprocess = self.CLIP_preprocess\n",
    "        \n",
    "        text = clip.tokenize([context]).to(device)\n",
    "        images = torch.stack(images).squeeze().to(device)\n",
    "        \n",
    "        image_features = CLIP_model.encode_image(images)\n",
    "        text_features = CLIP_model.encode_text(text)\n",
    "        \n",
    "        logits_per_image, logits_per_text = CLIP_model(images, text)\n",
    "        \n",
    "        \n",
    "    def evaluate_posterior(self, text_data, img_dict):\n",
    "        # I <- candidate images, T <- context, a <- ambiguous\n",
    "        # P(I|T) ~ P(I,T)/ <- CLIP\n",
    "        # 56.5% Accuracy 10% random\n",
    "        CLIP_model = self.CLIP_model\n",
    "\n",
    "        preds = []\n",
    "        golds = []\n",
    "        answers = []\n",
    "        partial_answers = []\n",
    "        for data_index in tqdm(text_data.keys()):\n",
    "            data = text_data[data_index]\n",
    "            context = data['context']; candidates = data['candidates']\n",
    "            target_word = data['target_word']\n",
    "            context = context.replace(target_word, '\\\"'+target_word+'\\\"')\n",
    "            \n",
    "            gold = data['gold']; gold_index = data['candidates'].index(gold)\n",
    "\n",
    "            text = clip.tokenize([context]).to(device)\n",
    "            with torch.no_grad():\n",
    "                images = [img_dict[candidate] for candidate in candidates]\n",
    "                images = torch.stack(images).squeeze().to(device)\n",
    "                image_features = CLIP_model.encode_image(images)\n",
    "                text_features = CLIP_model.encode_text(text)\n",
    "\n",
    "                logits_per_image, logits_per_text = CLIP_model(images, text)\n",
    "                probs = logits_per_text.softmax(dim=-1).cpu().numpy()\n",
    "                pred = np.argmax(probs[0])\n",
    "                \n",
    "                preds.append(data['candidates'][pred]) \n",
    "                golds.append(gold)\n",
    "                if pred == gold_index:\n",
    "                    answers.append(1)\n",
    "                else:\n",
    "                    answers.append(0)\n",
    "                \n",
    "                sorted_indexes = reversed(np.argsort(probs[0]))\n",
    "                \n",
    "                i = 1\n",
    "                #print(sorted_indexes)\n",
    "                for index in sorted_indexes:\n",
    "                    #print(index, gold_index)\n",
    "                    if index == gold_index:\n",
    "                        #partial_answers = 1/i\n",
    "                        partial_answers.append(1/i)\n",
    "                        break\n",
    "                    i+=1\n",
    "        return preds, golds, answers, partial_answers\n",
    "    \n",
    "    \n",
    "    def evaluate_bayesian_posterior(self, text_data, img_dict):\n",
    "        # P(I|T) -> \\sigma \\simga P(I|D,T)P(D|T)\n",
    "        # 75%\n",
    "        CLIP_model = self.CLIP_model\n",
    "\n",
    "        preds = []\n",
    "        golds = []\n",
    "        answers = []\n",
    "        partial_answers = []\n",
    "        #probs = []\n",
    "        for data_index in tqdm(text_data.keys()):\n",
    "            data = text_data[data_index]\n",
    "            context = data['context']; candidates = data['candidates']\n",
    "            target_word = data['target_word']\n",
    "            context = context.replace(target_word, '\\\"'+target_word+'\\\"')\n",
    "            \n",
    "            sense_definitions = data['sense_definitions']\n",
    "            sense_definitions = [context + ' : ' + sense_definition for sense_definition in sense_definitions]\n",
    "            \n",
    "            if not len(sense_definitions):\n",
    "                #print('no sense')\n",
    "                sense_definitions += [context]\n",
    "                \n",
    "            \n",
    "            gold = data['gold']; gold_index = data['candidates'].index(gold)\n",
    "            \n",
    "            \n",
    "\n",
    "            #text = clip.tokenize([context]).to(device)\n",
    "            with torch.no_grad():\n",
    "                context_text = clip.tokenize([context], truncate = True).to(device)\n",
    "                definition_text = clip.tokenize(sense_definitions, truncate = True).to(device)\n",
    "\n",
    "                images = [img_dict[candidate] for candidate in candidates]\n",
    "                images = torch.stack(images).squeeze().to(device)\n",
    "\n",
    "                # 1 answer and 9 distractors\n",
    "                image_features = CLIP_model.encode_image(images)\n",
    "                text_features = CLIP_model.encode_text(context_text)\n",
    "                # 4 senses in wordnet [4X512]\n",
    "                def_features = CLIP_model.encode_text(definition_text)\n",
    "                \n",
    "\n",
    "                \n",
    "                # probs text to def\n",
    "                # P(D_i|T)\n",
    "                # [1X4]\n",
    "                logits_per_definition = torch.matmul(text_features, def_features.T)\n",
    "                prob_dist_definitions = logits_per_definition.softmax(dim=-1)\n",
    "                \n",
    "                # P(I|T,D)\n",
    "                # [4 X 10] \n",
    "                logits_per_image, logits_per_text = CLIP_model(images, definition_text)\n",
    "                probs_per_image = logits_per_image.softmax(dim=-1)\n",
    "                probs_per_text = logits_per_text.softmax(dim=-1)\n",
    "\n",
    "                bayesian_probs = torch.matmul(prob_dist_definitions, probs_per_text).cpu().numpy()\n",
    "                pred = np.argmax(bayesian_probs)\n",
    "                \n",
    "                sorted_indexes = reversed(np.argsort(bayesian_probs[0]))\n",
    "                \n",
    "                i = 1\n",
    "                for index in sorted_indexes:\n",
    "                    if index == gold_index:\n",
    "                        #partial_answers = 1/i\n",
    "                        partial_answers.append(1/i)\n",
    "                        break\n",
    "                    i+=1\n",
    "                #ranks = [data['candidates'][index] for index in sorted_indexes]\n",
    "                \n",
    "                preds.append(data['candidates'][pred]) \n",
    "                golds.append(gold)\n",
    "                if pred == gold_index:\n",
    "                    answers.append(1)\n",
    "                else:\n",
    "                    answers.append(0)\n",
    "        return preds, golds, answers, partial_answers\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad6d32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "VWSD_CLIP = VWSD_CLIP_Zeroshot(CLIP_model, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74a1fef4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12869/12869 [16:18<00:00, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.69\n",
      "MRR: 82.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p_preds, p_golds, p_answers, p_partial_answers =  VWSD_CLIP.evaluate_posterior(text_data, img_dict)\n",
    "print(\"Accuracy:\", \"%.2f\"%(np.mean(p_answers)*100))\n",
    "print(\"MRR:\", \"%.2f\"%(np.mean(p_partial_answers)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc365f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 423), (1, 2099), (2, 316), (3, 193), (4, 94), (5, 68), (6, 61), (7, 40), (8, 27), (9, 20), (10, 18), (11, 13), (12, 13), (13, 10), (14, 14), (15, 9), (16, 18), (17, 4), (18, 11), (19, 5), (20, 6), (21, 3), (22, 3), (23, 2), (24, 3), (25, 3), (27, 3), (28, 2), (29, 3), (30, 1), (31, 2), (32, 1), (33, 2), (34, 3), (36, 1), (37, 1), (39, 2), (40, 1), (41, 1), (45, 5), (49, 1), (51, 2), (52, 3), (54, 1), (70, 2), (75, 1)]\n",
      "[(0, 1422), (1, 4991), (2, 1277), (3, 536), (4, 305), (5, 202), (6, 144), (7, 114), (8, 79), (9, 51), (10, 25), (11, 37), (12, 23), (13, 19), (14, 18), (15, 16), (16, 12), (17, 6), (18, 15), (19, 5), (20, 5), (21, 9), (22, 3), (23, 5), (24, 3), (25, 3), (26, 2), (27, 4), (28, 1), (29, 2), (31, 2), (33, 3), (34, 4), (35, 1), (39, 2), (41, 1), (44, 1), (45, 2), (47, 2), (57, 2), (75, 1)]\n",
      "Hits@1 |D^t|==0: 77.07\n",
      "Hits@1 |D^t|==1: 70.39\n",
      "Hits@1 |D^t|>1: 74.78\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "p_sense_nums_w = []\n",
    "p_sense_nums_r = []\n",
    "for t, p, g in zip(text_data, p_preds, p_golds):\n",
    "    if p != g:\n",
    "        #print(t, text_data[t]['context'], p, g, len(text_data[t]['sense_definitions']))\n",
    "        p_sense_nums_w.append(len(text_data[t]['wordnet_definitions']))\n",
    "    else:\n",
    "        p_sense_nums_r.append(len(text_data[t]['wordnet_definitions']))\n",
    "    index+=1\n",
    "    \n",
    "print(sorted(Counter(p_sense_nums_w).items()))\n",
    "print(sorted(Counter(p_sense_nums_r).items()))\n",
    "\n",
    "right_when_zero = sorted(Counter(p_sense_nums_r).items())[0][1]\n",
    "wrong_when_zero = sorted(Counter(p_sense_nums_w).items())[0][1]\n",
    "\n",
    "right_when_one = sorted(Counter(p_sense_nums_r).items())[1][1]\n",
    "wrong_when_one = sorted(Counter(p_sense_nums_w).items())[1][1]\n",
    "\n",
    "right_when_over_one = 0\n",
    "wrong_when_over_one = 0\n",
    "\n",
    "for s, c in sorted(Counter(p_sense_nums_w).items()):\n",
    "    if s > 1: wrong_when_over_one += c\n",
    "for s, c in sorted(Counter(p_sense_nums_r).items()):\n",
    "    if s > 1: right_when_over_one += c\n",
    "\n",
    "print('Hits@1 |D^t|==0: %.2f'%(right_when_zero/(right_when_zero + wrong_when_zero)*100))\n",
    "print('Hits@1 |D^t|==1: %.2f'%(right_when_one/(right_when_one + wrong_when_one)*100))\n",
    "print('Hits@1 |D^t|>1: %.2f'%(right_when_over_one/(right_when_over_one + wrong_when_over_one)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00247246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9355"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dcc7842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12869/12869 [20:09<00:00, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.47\n",
      "MRR: 89.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bp_preds, bp_golds, bp_answers, bp_partial_answers =  VWSD_CLIP.evaluate_bayesian_posterior(text_data, img_dict)\n",
    "print(\"Accuracy:\", \"%.2f\"%(np.mean(bp_answers)*100))\n",
    "print(\"MRR:\", \"%.2f\"%(np.mean(bp_partial_answers)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db9b6629-a32f-4e27-9d1d-6e3ae6737b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 282), (1, 967), (2, 276), (3, 174), (4, 80), (5, 62), (6, 58), (7, 34), (8, 24), (9, 13), (10, 18), (11, 9), (12, 13), (13, 10), (14, 13), (15, 8), (16, 19), (17, 5), (18, 9), (19, 4), (20, 5), (21, 5), (22, 1), (23, 2), (24, 2), (25, 4), (27, 3), (28, 1), (29, 2), (30, 1), (31, 2), (32, 1), (33, 2), (34, 3), (36, 1), (39, 2), (41, 1), (45, 5), (51, 2), (52, 1), (54, 1), (70, 1), (75, 1)]\n",
      "[(0, 1563), (1, 6123), (2, 1317), (3, 555), (4, 319), (5, 208), (6, 147), (7, 120), (8, 82), (9, 58), (10, 25), (11, 41), (12, 23), (13, 19), (14, 19), (15, 17), (16, 11), (17, 5), (18, 17), (19, 6), (20, 6), (21, 7), (22, 5), (23, 5), (24, 4), (25, 2), (26, 2), (27, 4), (28, 2), (29, 3), (31, 2), (33, 3), (34, 4), (35, 1), (37, 1), (39, 2), (40, 1), (41, 1), (44, 1), (45, 2), (47, 2), (49, 1), (52, 2), (57, 2), (70, 1), (75, 1)]\n",
      "Hits@1 |D^t|==0: 84.72\n",
      "Hits@1 |D^t|==1: 86.36\n",
      "Hits@1 |D^t|>1: 77.68\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "pb_sense_nums_w = []\n",
    "pb_sense_nums_r = []\n",
    "for t, p, g in zip(text_data, bp_preds, bp_golds):\n",
    "    if p != g:\n",
    "        #print(t, text_data[t]['context'], p, g, len(text_data[t]['sense_definitions']))\n",
    "        pb_sense_nums_w.append(len(text_data[t]['wordnet_definitions']))\n",
    "    else:\n",
    "        pb_sense_nums_r.append(len(text_data[t]['wordnet_definitions']))\n",
    "    index+=1\n",
    "print(sorted(Counter(pb_sense_nums_w).items()))\n",
    "print(sorted(Counter(pb_sense_nums_r).items()))\n",
    "\n",
    "right_when_zero = sorted(Counter(pb_sense_nums_r).items())[0][1]\n",
    "wrong_when_zero = sorted(Counter(pb_sense_nums_w).items())[0][1]\n",
    "\n",
    "right_when_one = sorted(Counter(pb_sense_nums_r).items())[1][1]\n",
    "wrong_when_one = sorted(Counter(pb_sense_nums_w).items())[1][1]\n",
    "\n",
    "right_when_over_one = 0\n",
    "wrong_when_over_one = 0\n",
    "\n",
    "for s, c in sorted(Counter(pb_sense_nums_w).items()):\n",
    "     if s > 1: wrong_when_over_one += c\n",
    "for s, c in sorted(Counter(pb_sense_nums_r).items()):\n",
    "     if s > 1: right_when_over_one += c\n",
    "    \n",
    "print('Hits@1 |D^t|==0: %.2f'%(right_when_zero/(right_when_zero + wrong_when_zero)*100))\n",
    "print('Hits@1 |D^t|==1: %.2f'%(right_when_one/(right_when_one + wrong_when_one)*100))\n",
    "print('Hits@1 |D^t|>1: %.2f'%(right_when_over_one/(right_when_over_one + wrong_when_over_one)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdef43c-d8c7-4a41-82b1-6904960e5e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
